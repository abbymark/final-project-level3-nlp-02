{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import notebook_login\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabbymark\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/final_project/final-project-level3-nlp-02-amc_/runs/2erj8780\" target=\"_blank\">restful-sky-1</a></strong> to <a href=\"https://wandb.ai/final_project/final-project-level3-nlp-02-amc_\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/final_project/final-project-level3-nlp-02-amc_/runs/2erj8780?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fdd15d4ad30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "wandb.init(\n",
    "    entity=\"final_project\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5493871b524e38b0cee11141fa56a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset magazine_summarization/Magizine Summarization to /opt/ml/.cache/huggingface/datasets/metamong1___magazine_summarization/Magizine Summarization/1.0.0/506cb41eb0b96b084eafa5dd5fe3b51ff0d1061256700adf1aa92d3b19762c36...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4ec259870b4961983beb695dc74e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6347c89d1544e2895c8916b2ea7c878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f991bafa264be8a826c1726f39a4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/72.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4243822ac37e4207a6b02080f4691ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56863f934bb6416a9931ebaaab602a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad16c7fa3c8949e3a948315970fd08a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset magazine_summarization downloaded and prepared to /opt/ml/.cache/huggingface/datasets/metamong1___magazine_summarization/Magizine Summarization/1.0.0/506cb41eb0b96b084eafa5dd5fe3b51ff0d1061256700adf1aa92d3b19762c36. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c625ee2aca4c40bfabde909acc9ce904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api_token = os.getenv('USE_AUTH_TOKEN')\n",
    "dataset = datasets.load_dataset('metamong1/summarization_magazine', use_auth_token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['doc_id', 'title', 'text', 'doc_type', 'file'],\n",
       "        num_rows: 73640\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['doc_id', 'title', 'text', 'doc_type', 'file'],\n",
       "        num_rows: 18411\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking dataset content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(dataset, datasets.dataset_dict.DatasetDict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=seed):\n",
    "    if isinstance(dataset, datasets.dataset_dict.DatasetDict):\n",
    "        sample = dataset['train'].shuffle(seed=seed).select(range(num_samples))\n",
    "    elif isinstance(dataset, datasets.arrow_dataset.Dataset):\n",
    "        sample = dataset.shuffle(seed=seed).select(range(num_samples))\n",
    "    else:\n",
    "        raise ValueError('Inappropriate dataset.')\n",
    "    for example in sample:\n",
    "        print(f\"\\n'>> Title: {example['title']}'\")\n",
    "        print(f\"'>> Text: {example['text']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 'A201008192682',\n",
       " 'title': '횡적등방성 매질에서 중합전 역시간 구조보정',\n",
       " 'text': '역시간 구조보정은 음원영역 파동장 외삽과 수진기영역 파동장 외삽의 상호상관으로 지층구조를 영상화하는 방법으로 복잡한 등방성 매질 층서구조를 영상화하는데 주로 이용된다. 그러나 일반적으로 지구내부 지층구조는 이방성 특성을 지니고 있으므로 이방성을 고려한 구조보정 기술이 필요하다. 여기에서는 편미분 파동장과 음원모음의 내적에 의한 알고리즘과 가상음원과 역전파 파동장과의 내적에 의한 알고리즘을 이용하여 횡적등방성 매질에서 역시간 구조보정 기술을 개발하고자 하였다. 단순 이방성 지층모델에 대한 수치모형실험 결과, 두 가지 방법에 의한 지층단면도 영상은 거의 차이가 없어 가상음원과 역전파 파동장과의 내적으로 구조보정을 실시하는 것이 효과적임을 알 수 있었다. 수평적으로 속도가 변하는 이방성 매질 지층구조에서 편미분 파동장을 구하지 않고 영상화 할 수 있음을 알 수 있었다.',\n",
       " 'doc_type': '논문',\n",
       " 'file': '논문요약_0206_0.json'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/1.4.0/24bb09528ebb04fdc6aafb6e110202e52fbb818c0f204839bc833d8ce1e86a5f/cache-93a7be41ce043bd9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: 민주주의 관점으로 본 국가기록관리체계 평가와 전망'\n",
      "'>> Text: 본 논문은 국가기록관리체계를 민주주의 관점에서 보았다. 지난 10년의 국가기록관리체계를 평가하고 새로운 국가기록관리체계를 전망하기위해서는 민주주의가 우선이 되어야 할 것 같다. 지난 10년의 아카이브가쭈그러진 아카이브였다면, 새로운 아카이브는 어떤 아카이브이어야 할까? 쭈그러진 깡통을 펴듯이 망가지기 전의 상태로 복구하는 게 필요한 일인줄 알면서도 새로운 기록풍경을 그리는 것도 그 못지않게 중요하다고 보았다. 본 논문은 기본적으로 민주주의의 가치를 제도화하는 아카이브 전망에대한 것이다. 나아가 일상적 민주주의에서 아카이브는 무엇을 할 수 있을지도 짚어보았다. 이를 위해 그간의 국가기록관리기구 개편 제안을 체계적으로 검토했다. 그 다음에는 공공기록관 기록관리직의 목소리를 재현해보았다. 기록관리직은 지난 10년 동안 기록공동체와 우리 사회가 일군 사회적자산이기 때문에 그 목소리가 무엇을 원하는지 들어야 한다고 판단했기 때문이다. 기록은 이제 단순히 통치의 수단이 아니라 그 통치의 정통성을 규정하는 통치의 기반이 되었다. 이처럼 기록의 사회적 역할과 의미가 달라졌다. 1999년 시점이 아닌 2017년 시점에서, 국가아카이브의 기록풍경을 다시 그려야 할 것이다. 이런 과제를 위해서는 무엇보다도 민주주의 관점이 필요하다고 생각한다.'\n",
      "\n",
      "'>> Title: 조선의 대일 교화 양상과 그 기저 (朝鮮의 對日 敎化 樣相과 그 基底)'\n",
      "'>> Text: 조선전기는 왜구의 잦은 침탈로 인해 일본과의 외교적 해결이 절실히 요구되던 때였다. 그러나 막부의 왜구 통제력 부족으로 교섭이 번번이 무위로 돌아갔다. 그와 같은 상황이 지속되자 명쾌한 대책을 마련하지 못한 조선은 信義를 잃은 일본에 대하여 夷狄으로 대하거나 小國으로 여기는 입장을 취하였다. 이러한 당시의 대일 관계는 문인들에 의해 시문으로 구현되었다. 하지만 시문을 살펴보면, 현안인 왜구를 근절하는 데에만 집중한 나머지 조일 간의 다양한 교류의 면모는 찾을 수 없고 왜구 금압이라는 한 측면에만 경사되어 있음을 발견하게 된다. 이것은 왜구 문제가 조일 간의 정상적인 문화 교류를 저해하였다는 점에서 안타까운 일이 아닐 수 없고 문학사에서도 아쉬움으로 남는 부분이다. 왜구의 창궐이 심할수록 교화의 당위성은 제고되었으나 직접 왜구를 대면하여 교화할 길이 없었던 당대 문인들은 일본국왕사나 통신사에게 주는 시문으로나마 교화의 뜻을 일본에 전하고자 하였다. 그 대상이 왜구여야 함에도 실체가 모호하였기에 일본국왕을 상대로 전개될 수밖에 없는 한계가 있었다. 본고에서는 조일 양국의 교류에 대한 연구가 유형적인 것에 편향되었다는 반성에서, 조선전기 시문에 나타난 대일 교화의 양상과 그 기저를 밝히는 데 중점을 두었다. 교화의 양상으로는 먼저 조선이 교화의 주체로 나서고자 箕子와 찬란한 문물로써 태평시대임을 부각시키려 한 것을 들 수 있다. 그것은 조선의 정치가 안정되고 문화가 난숙하였던 기반 위에서 나왔으며 그 동인은 ‘恕’와 ‘位育’이라는 유가의 치도였다. 우수한 문물로 인한 문화적 우월감과 유가의 불가에 대한 우위는 ‘兩國一家’라는 교화의 기치로 이어진다. 교화라는 말이 관념적이라서 양국일가에 장애가 되는 험난한 동해를 교화로 고요히 하려는 관념성을 띠었고, 더 나아가 교화를 ‘雲雨’나 ‘雨露’로써 비유하여 표현하기도 하였다. 이러한 교화의 양상을 보인 기저에는 ‘仁’과 ‘圓’이 있었다. 교화의 기저 가운데 ‘仁’은 무력보다는 덕을 높이고 따스한 햇볕과 같이 만물을 비추어 소생시키는 지향을 지녔다. 우주론적 인식에 근거하면 일본은 ‘仁’의 방향이 되는데, 그 점은 실제 왜구가 벌인 만행과는 모순되지만 왜구를 금제할 이론적 근거이면서 동시에 그들의 ‘인’을 감발시키는 계기가 되었다. ‘圓’은 만물의 운행 원리로, 조일 간의 교린에도 적용되기를 바랐다. ‘圓’의 실제적 의미는 교린에서의 信義를 뜻하였지만, 교화의 기저 가운데 하나로서 교화가 단절되지 않도록 도와주는 기능이었다. ‘仁’과 ‘圓’의 층위가 달라 구분이 무의미하기는 하지만 ‘仁’이 일본의 人性을 계발하는 교화의 핵심적 기저라면 ‘圓’은 그것을 보조하는 주변적 기저라고 할 수 있겠다.'\n",
      "\n",
      "'>> Title: 농촌지역 노령인구의 통행패턴 분석- 경상북도 봉화군 지역을 중심으로 -'\n",
      "'>> Text: 농촌이라는 지역적 조건과 노인이라는 신체적, 경제적, 그리고 사회적 조건을 고려할 때 우리나라 농촌지역에 거주하는 노인들은 이동 및 접근의 제약으로 인하여 공간적 고립 및 사회적 배제과정에 노출될 가능성이 매우 높은 집단이라고 할 수 있다. 그러나 특정 집단의 교통으로 인한 사회적 배제 문제를 분석하기 위해서는 이들의 개인적 특성에 따른 통행패턴에 대한 이해가 전제되어야 한다. 하지만 우리나라에서는 농촌노인들의 통행에 관련된 연구 성과가 매우 미흡하며 따라서 이들 인구의 개인적 특성에 따른 통행패턴에 대한 연구의 필요성이 매우 크다. 이러한 배경에서 본 연구는 농촌지역에 거주하는 노인들을 대상으로 이들의 개인적 특성과 통행패턴 간의 연관성을 분석하였다. 연구지역 노인들의 통행특성은 이들의 신체적, 경제적, 그리고 사회적 배경 등의 요인들에 따라 매우 다양하게 나타나고 있다. 특히 농촌지역이라는 지역적 특성으로 인하여 이들의 신체적 건강상태 및 경제적 능력 등에 따른 자가용 승용차 이용 정도는 이들의 이동과정에 매우 큰 영향을 미치고 있다. 그러나 현실적으로 우리나라 농촌에 거주하는 많은 노인들은 자가용 이용 능력이 없으며, 또한 현재 농촌에서 운영 중인 버스를 중심으로 한 대중교통체계가 자가용 승용차와 같은 개인적이며 유연적인 통행을 제공할 수 없다. 이러한 점들을 고려할 때 우리나라 농촌노인들은 이동의 제약으로 인한 공간적 고립, 그리고 더 나아가 교통으로 인한 사회적 배제 과정에 노출 될 수 있는 가능성이 매우 높다고 할 수 있다. 따라서 앞으로 본 연구결과를 바탕으로 이러한 농촌노인들의 개인적 특성에 따른 통행특성 그리고 이에 따른 이동의 제약 등의 요인들이 이들의 공간적 고립 내지는 사회적 배제 과정에 미치는 영향에 대한 연구의 필요성이 매우 절실하다.'\n"
     ]
    }
   ],
   "source": [
    "show_samples(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/1.4.0/24bb09528ebb04fdc6aafb6e110202e52fbb818c0f204839bc833d8ce1e86a5f/cache-93a7be41ce043bd9.arrow\n"
     ]
    }
   ],
   "source": [
    "sample_size = 5000\n",
    "sample_training_dataset = dataset['train'].shuffle(seed=seed).select(range(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/1.4.0/24bb09528ebb04fdc6aafb6e110202e52fbb818c0f204839bc833d8ce1e86a5f/cache-97e84a9dc97fba8d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: 서방정토 극락세계의 존재에 관한 연구'\n",
      "'>> Text: 본 논문에서는 서방정토극락세계와 아미타불의 존재와 장엄에 대하여 살펴보았다. 이러한 국토와 부처님은 법장비구의 출가와 발원에서 시작되었다. 그 동기는 이상국가의 건설과 지도자의 탄생을 갈망하는 마음이었다. 48대원의 발원과 오랜 수행으로 극락정토가 이루어졌고, 아미타불이 탄생하였다. 극락정토의 依報莊嚴은 대지와 寶樹와 法音樹, 蓮池, 功德水 등으로 표현되어 있다. 기세간적인 장엄은 물질적인 장엄이다. 극락정토는 물질적은 절대적으로 풍요로운 세계이다. 조금도 부족함이 없는 세계, 완전히 만족한 세계를 표방하고 있다. 그 근거로 각 경전에서 설하는 증거를 제시하여 실존함을 증명코자 하였다. 다음으로 아미타불과 성중들에 대한 正報莊嚴을 살펴보았다. 아미타불은 10겁전에 성불하였으며, 無量光, 無量壽의 부처님이다. 영원한 지혜광명의 부처님이고, 영원한 생명의 부처님인 것이다. 이에 대해 각 경전과 논서들을 증거로 제시하면서 그 존재와 실재를 증명코자 하였다. 이는 정신적인 장엄이며, 안락의 세계이다. 마지막으로 指方立相的인 정토와 아미타불의 존재에 대한 믿음을 밝혔다. 극락정토는 서방으로 십만억불토를 지난 곳에 분명히 존재한다고 정토계 경전에서는 설하고 있다. 그러나 어리석은 중생들은 이에 대해 의혹심을 가지면서 믿고 있다. 이를 반신반의라고 할 수 있을 것이다. 그들은 邊地에 胎生으로 태어난다고 한다. 특히 원효는 정토와 아미타불의 존재를 믿지 않는 것은 부처님의 五智를 의심하는 것이므로 邊地에 태어난다고 하였다. 그러면서 그는 仰信, 應信, 伏信을 설하고 있다. 그 경지는 중생의 알음알이로 알 수 있는 경지가 아니므로 부처님의 말씀을 믿어야 한다고 하였다. 오늘날 불자들 가운데에는 의혹중생이 많으며, 唯心淨土로 이해하여 관념론적인 정토로 해석하는 사람들이 많다. 이는 참으로 경계해야 할 신행방법이라고 아니할 수 없다.'\n",
      "\n",
      "'>> Title: 북한이탈주민 지원 인력의 소진 요인과 극복방안에 관한 연구'\n",
      "'>> Text: 본 연구의 목적은 북한이탈주민 지원 인력들의 소진 요인과 극복 방안들을 군집분석하여 이에 대한 예방 및 대안을 마련하는 것이다. 이를 위해 북한이탈주민 지원 인력 12명을 대상으로 개인 및 집단 면담을 실시하였으며, 응답 자료를 통합하여 소진 어려움 199개, 극복 방안 137개의 아이디어를 수집하였다. 이를 토대로 최종 진술문을 각각 49개와 35개로 축약하였으며, 연구대상자 12명에게 중요도를 평정 받았다. 연구결과는 북한이탈주민 지원 인력들이 겪는 소진 어려움에 대한 2개 차원(환경적 요인-업무특성, 소진의 주요 원인-소진의 주요 결과)과 5개 군집(조직 분위기, 감정조절 및 소진관리의 어려움, 일에 대한 부담과 대인문제, 열악한 근무조건 및 환경, 신체적 소진 및 냉담), 극복방안에 대한 2개 차원(소극적 대처-적극적 대처, 개인적 대처-조직 및 사회적 대처)과 4개의 군집(북한이탈주민 지원업무에 대한 인식의 재구조화, 조직적 차원의 개선과 사회적 지지, 스트레스 관리, 일에 대한 조망과 소진프로그램)으로 구성된 개념도를 도출하였다. 이러한 연구결과를 토대로 북한이탈주민 인력에 대한 소진 예방 및 추후 연구를 제언하였다.'\n",
      "\n",
      "'>> Title: Interface Assessment를 통한 액티브 시니어의 사용자 경험 분석'\n",
      "'>> Text: 본 논문은 기존 노년층과는 다른 특성을 보이는 액티브 시니어의 사용자 경험 문제를 도출해 내기 위한 연구로 먼저 선행 연구분석을통하여‘Visible’, ‘Desired Outcome’, ‘Immediate Feedback’, ‘Intuitiveness’, ‘Perceived Ease of Use’의다섯가지요소를사용자 interaction의 초기단계를 이루는 요소로 추출하였고이를 기반으로Interface 사용중에 사용자의행위와인지 내용을 분석하였다. 이를 통해 사용과정에서 생기는 문제점을 도출하였으며, 다섯 가지 요소와 사용자의 주관 평가 간의 상관관계를 분석하였다. 사용자경험의주관평가에는PSSUQ를사용하였으며SPSS 22 버전을사용하여pearson 상관분석을실시하였다. 본 논문의연구결과는다음과같다. 첫째, App 사용시액티브시니어사용자들이겪는가장큰 문제는desired outcome차원의문제로볼수 있다. 둘째, interface assessment 다섯 가지 요소 중 ‘Desired Outcome’, ‘Perceived Ease of Use’ 두 가지 요소만이 PSSUQ 설문 결과와통계적으로유의미한상관관계를보이는것으로나타났으며나머지‘Visible’, ‘Immediate Feedback’, ‘Intuitiveness’의 세 요소는사용자의주관평가와상관관계를보이지않았다. 본논문의연구결과에의하면액티브시니어는기존의노년층과는다른특징을가지고 있어'Desired Outcome'과'Perceived ease of use'차원의문제가더 많은영향을미치는요소로볼 수 있으며기존의연구에서중요한 요소로 거론한 'Visible', 'Immediate feedback', 'Intuitiveness'는 명확한 상관관계가 없는 것으로 볼 수 있다. 이는 기존노년층과달리액티브시니어의경우PC나스마트폰사용경험의누적으로인하여visible, immediate feedback, intuitiveness 등의요소에어려움을적게겪기때문인것으로보인다. 본논문의연구결과는다양한수요를보이고있는액티브시니어용App의개발에 의미 있게 활용될 것이다. '\n"
     ]
    }
   ],
   "source": [
    "show_samples(sample_training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_checkpoint = \"gogamza/kobart-summarization\"\n",
    "model_checkpoint = 'encoder_decoder_pruned_last_3'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [12147, 10608, 14106, 14403, 14353, 26200, 24224, 14667, 14150, 14803, 24110, 11465, 9754, 232], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"제목 생성을 위한 요약 모델을 이제부터 만들어 봅시다!\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['제',\n",
       " '목',\n",
       " '▁생',\n",
       " '성을',\n",
       " '▁위한',\n",
       " '▁요약',\n",
       " '▁모델을',\n",
       " '▁이제',\n",
       " '부터',\n",
       " '▁만들어',\n",
       " '▁봅',\n",
       " '시',\n",
       " '다',\n",
       " '!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['text'], max_length=max_input_length, truncation = True, #padding=True\n",
    "    )\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples['title'], max_length=max_target_length, truncation=True, #padding=True\n",
    "        )\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c07104a4e4745cb8b75d67be6efa9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = sample_training_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1559c12a154706a3222a1ee9d37c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_eval_datasets = dataset['validation'].select(range(500)).map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_metric\n",
    "# rouge_score = load_metric('rouge')\n",
    "\n",
    "import os, sys\n",
    "sys.path.append('/opt/ml/final-project-level3-nlp-02')\n",
    "from rouge import compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(precision=0.7969924812030075, recall=0.9375, fmeasure=0.8615384615384615)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summary = [\"이번 제목 생성 테스크 진짜 진짜 잘하고 싶다. 두번째줄은 작동 안한다고?\", '이번에 잘되면 정말 좋겠다']\n",
    "reference_summary = [\"이번 제복 생성 테스크 잘하고 싶다. 두번째 작동 안한다고?\", '이번에 잘되면 좋겠다']\n",
    "# generated_summary = \"I absolutely loved reading the Her Games\"\n",
    "# reference_summary = \"I loved reading the Hunger Games\"ung\n",
    "scores = compute(\n",
    "    predictions=generated_summary, references=reference_summary, tokenizer=tokenizer\n",
    ")\n",
    "scores['rouge1'].mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.7368421052631579, recall=0.875, fmeasure=0.7999999999999999), mid=Score(precision=0.7969924812030075, recall=0.9375, fmeasure=0.8615384615384615), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.5555555555555556, recall=0.6666666666666666, fmeasure=0.606060606060606), mid=Score(precision=0.6111111111111112, recall=0.7333333333333334, fmeasure=0.6666666666666665), high=Score(precision=0.6666666666666666, recall=0.8, fmeasure=0.7272727272727272)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.7368421052631579, recall=0.875, fmeasure=0.7999999999999999), mid=Score(precision=0.7969924812030075, recall=0.9375, fmeasure=0.8615384615384615), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.7368421052631579, recall=0.875, fmeasure=0.7999999999999999), mid=Score(precision=0.7969924812030075, recall=0.9375, fmeasure=0.8615384615384615), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923))}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "def one_sentence_title(text):\n",
    "    return kss.split_sentences(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Korean Sentence Splitter]: Initializing Pynori...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 논문은 국가기록관리체계를 민주주의 관점에서 보았다.\n"
     ]
    }
   ],
   "source": [
    "print(one_sentence_title(sample_training_dataset['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(dataset, tokenizer):\n",
    "    summaries = [one_sentence_title(text) for text in dataset['text']]\n",
    "    return compute(predictions=summaries, references=dataset['title'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 26.39, 'rouge2': 14.87, 'rougeL': 23.42, 'rougeLsum': 23.5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = evaluate_baseline(dataset['validation'].shuffle().select(range(10)), tokenizer)\n",
    "rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "rouge_dict = dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/final/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 2\n",
    "\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = 100 #len(tokenized_datasets) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    # output_dir=f'{model_name}-finetuned-paper-sample-size-1000',\n",
    "    output_dir=f'{model_name}-finetuned-paper-sample-size-1000-pruned',\n",
    "    evaluation_strategy='steps', #'epoch',\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay = 0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to='wandb'\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    # decoded_preds = ['\\n'.join(kss.split_sentences(pred.strip())) for pred in decoded_preds]\n",
    "    # decoded_labels = ['\\n'.join(kss.split_sentences(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    result = compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Extract the median scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets[5]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_return = ['input_ids', 'labels', 'attention_mask']\n",
    "tokenized_datasets.set_format(type='torch', columns = columns_to_return)#, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]]), 'input_ids': tensor([[10888, 14396, 19255,  ...,     3,     3,     3],\n",
       "        [16446, 12126, 14575,  ...,  3020, 18037, 14098]]), 'labels': tensor([[15352, 14453, 14073, 16439, 14285, 14518, 17469, 15095, 20044, 14653,\n",
       "         11863, 14718,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [16446, 12024, 14029, 12041, 14139, 13714, 14256, 17664, 14028, 14040,\n",
       "         12123, 14338,  4543,  8813, 12024,  1700,  3486,  4400,  1700,  4336,\n",
       "          2682,  1700,  4823,  5996,  9120, 14028,  1700,  3095,  3704,   240]]), 'decoder_input_ids': tensor([[    2, 15352, 14453, 14073, 16439, 14285, 14518, 17469, 15095, 20044,\n",
       "         14653, 11863, 14718,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
       "        [    2, 16446, 12024, 14029, 12041, 14139, 13714, 14256, 17664, 14028,\n",
       "         14040, 12123, 14338,  4543,  8813, 12024,  1700,  3486,  4400,  1700,\n",
       "          4336,  2682,  1700,  4823,  5996,  9120, 14028,  1700,  3095,  3704]])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tokenized_datasets[i] for i in range(2)]\n",
    "data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_eval_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running training *****\n",
      "  Num examples = 5000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 04:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.018900</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.764400</td>\n",
       "      <td>16.678900</td>\n",
       "      <td>26.977500</td>\n",
       "      <td>27.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.022400</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.740300</td>\n",
       "      <td>16.622000</td>\n",
       "      <td>27.049700</td>\n",
       "      <td>27.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.007000</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.795800</td>\n",
       "      <td>16.621600</td>\n",
       "      <td>27.007700</td>\n",
       "      <td>26.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.017400</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.807100</td>\n",
       "      <td>16.603000</td>\n",
       "      <td>27.015200</td>\n",
       "      <td>26.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.043000</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.732300</td>\n",
       "      <td>16.609000</td>\n",
       "      <td>27.006800</td>\n",
       "      <td>26.964100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.025700</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.698400</td>\n",
       "      <td>16.600600</td>\n",
       "      <td>27.014700</td>\n",
       "      <td>26.995100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.944200</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.731900</td>\n",
       "      <td>16.636900</td>\n",
       "      <td>27.000700</td>\n",
       "      <td>26.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.035500</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>16.636300</td>\n",
       "      <td>27.013600</td>\n",
       "      <td>26.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.974700</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.801300</td>\n",
       "      <td>16.634700</td>\n",
       "      <td>27.031200</td>\n",
       "      <td>27.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.011800</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.787500</td>\n",
       "      <td>16.644500</td>\n",
       "      <td>27.056000</td>\n",
       "      <td>26.980900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.032100</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.777600</td>\n",
       "      <td>16.598700</td>\n",
       "      <td>26.996900</td>\n",
       "      <td>26.979600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.032400</td>\n",
       "      <td>3.523563</td>\n",
       "      <td>29.758600</td>\n",
       "      <td>16.595000</td>\n",
       "      <td>26.981100</td>\n",
       "      <td>27.008400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-500\n",
      "/opt/conda/envs/final/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Configuration saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-500/config.json\n",
      "Model weights saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-1000\n",
      "/opt/conda/envs/final/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Configuration saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-1000/config.json\n",
      "Model weights saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in encoder_decoder_pruned_last_3-finetuned-paper-sample-size-1000-pruned/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: doc_type, title, text, doc_id, file.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=2.0162662963867186, metrics={'train_runtime': 244.8054, 'train_samples_per_second': 40.849, 'train_steps_per_second': 5.106, 'total_flos': 1418176574521344.0, 'train_loss': 2.0162662963867186, 'epoch': 2.0})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26863/2732109216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uing Accelerate(Raw pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/gogamza/kobart-summarization/resolve/main/config.json from cache at /opt/ml/.cache/huggingface/transformers/1c32baaf6a1067a5e27a0dfbac0a3d23a86d958ab10b092d5ea4150bd451de17.4e52ef6c87e6938c92ba0d19888607d76e30e950e81060a8fa6cb1189c93614d\n",
      "/opt/conda/envs/final/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.11.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gogamza/kobart-summarization/resolve/main/pytorch_model.bin from cache at /opt/ml/.cache/huggingface/transformers/f30ba9ba60f377194e6a39913246c76f6dcac8158e399598ed56fec262103dba.b063b56b256aaf29f8c7c67e318ed78b83b9381147ac794d0df9ef0399066ea7\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-summarization.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_eval_datasets,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 2\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [preds.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch['labels']\n",
    "\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch['labels'], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # Replace -100 in the labels as we can't decode them\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_toekns = True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_toekns=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "    #         rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # # Compute metrics\n",
    "    # result = rouge_score.compute()\n",
    "\n",
    "    # # Extract the median ROUGE scores\n",
    "    # result = {key: value.mid.f}#####################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c127566a734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kobart-summarization-finetuned-paper-sample-size-1000/checkpoint-1000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained('kobart-summarization-finetuned-paper-sample-size-1000/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/final/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summzrizer = pipeline('summarization', model='kobart-summarization-finetuned-paper-sample-size-1000/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7000\n",
    "title = dataset['validation'][idx:idx+10]['title']\n",
    "text = dataset['validation'][idx:idx+10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['우리나라 기능직공무원의 직무만족에 미치는 요인 및 영향 분석',\n",
       " '아파트시장의 네트워크 효과',\n",
       " '한반도의 지정학적 의미에 대한 중국 정치엘리트의 전통적 인식',\n",
       " '한류열풍 속 대중문화를 통한 아시아 선교의 가능성',\n",
       " '혐기소화공정에서 항생항균물질이 메탄생성에 미치는 영향',\n",
       " '일본 공립도서관의 유형별 특성 분석 - 서비스내용과 서비스공간의 연계적 고찰을 중심으로 -',\n",
       " '소셜데이터 분석 및 인공지능 알고리즘 기반 범죄 수사 기법 연구',\n",
       " '소프트웨어 보안약점의 중요도에 대한 정량 평가 기준 연구',\n",
       " '동북아 안보환경에서 스텔스 전투기의 전략적 유용성과 한국 공군에 주는 함의',\n",
       " '기계설계분야 중견 엔지니어의 일과 학습에 관한 내러티브 연구: 엔지니어의 직무관련학습의 맥락과 공학교육에 대한 시사점 찾기']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"미디어 경제에서의 '도덕경제론' 이해 - - - - - - - - -\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summzrizer('근대 경제학에서는 행위의 합리성 문제를 비용 대 편익이라는 효율성 측면에서 접근하는데, 이러한 사고방식은 경제학을 넘어 사회과학 전반으로 널리 확산되 었다. 하지만 경제적 논리로는 설명하기 어렵거나 바람직하지 않은 결과를 낳은 현상도 많이 존재한다. 특히 도덕이나 규범은 경제 현상의 작동 방식에도 영향을 미치기 때문에 이를 설명하는 확장된 경제 이론이 필요하다. 도덕경제론은 바로 이러한 문제를 다루는 접근 방식이다. 이에 따르면 경제 활동에서 개인의 효용 극대화와 합리적 선택을 강조하는 경제학의 기본 가정 역시 초시대적으로 통용 되는 가치가 아니라 자본주의 등장 이후에 형성된 역사적 현상에 불과하다. 경제 적 원칙은 당대의 도덕적 규범에 의해 구성되는 상대적인 가치이기 때문에, 경제 활동이나 영역과 관련된 규범적 측면을 고려해 재구성해야 한다. ‘도덕경제 (moral economy)’론은 바로 이처럼 경제 현상에서 규범이나 문화의 역할 문제 를 다루는 접근 방식이다. 이러한 시도는 경제와 관련된 사회 현상을 이해하는 데 에서 경제학적 접근 방식의 편협성과 한계를 해결하는 데에도 풍부한 시사점을 줄수있을것이다. 이논문은기존의도덕경제론에서다룬주요쟁점과개념을 소개하고, 이 논의가 미디어 경제를 이해하는 데 주는 함의, 쟁점 등을 검토한다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.42857142857142855, recall=0.16666666666666666, fmeasure=0.24), mid=Score(precision=0.42857142857142855, recall=0.16666666666666666, fmeasure=0.24), high=Score(precision=0.42857142857142855, recall=0.16666666666666666, fmeasure=0.24)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.16666666666666666, recall=0.058823529411764705, fmeasure=0.08695652173913045), mid=Score(precision=0.16666666666666666, recall=0.058823529411764705, fmeasure=0.08695652173913045), high=Score(precision=0.16666666666666666, recall=0.058823529411764705, fmeasure=0.08695652173913045)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.2857142857142857, recall=0.1111111111111111, fmeasure=0.16), mid=Score(precision=0.2857142857142857, recall=0.1111111111111111, fmeasure=0.16), high=Score(precision=0.2857142857142857, recall=0.1111111111111111, fmeasure=0.16)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.2857142857142857, recall=0.1111111111111111, fmeasure=0.16), mid=Score(precision=0.2857142857142857, recall=0.1111111111111111, fmeasure=0.16), high=Score(precision=0.2857142857142857, recall=0.1111111111111111, fmeasure=0.16))}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute(\n",
    "    predictions=['도덕경제론과 미디어 경제 연구'], references=[\"미디어 경제에서의 '도덕경제론' 이해 - - - - - - - - -\"], tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '근대 경제학에서는 행위의 합리성 문제를 비용 대 편익이라는 효율성 측면에서 접근하는데, 이러한 사고방식은 경제학을 넘어 사회과학 전반으로 널리 확산되 었다. 하지만 경제적 논리로는 설명하기 어렵거나 바람직하지 않은 결과를 낳은 현상도 많이 존재한다. 특히 도덕이나 규범은 경제 현상의 작동 방식에도 영향을 미치기 때문에 이를 설명하는 확장된 경제 이론이 필요하다. 도덕경제론은 바로 이러한 문제를 다루는 접근 방식이다. 이에 따르면 경제 활동에서 개인의 효용 극대화와 합리적 선택을 강조하는 경제학의 기본 가정 역시 초시대적으로 통용 되는 가치가 아니라 자본주의 등장 이후에 형성된 역사적 현상에 불과하다. 경제 적 원칙은 당대의 도덕적 규범에 의해 구성되는 상대적인 가치이기 때문에, 경제 활동이나 영역과 관련된 규범적 측면을 고려해 재구성해야 한다. ‘도덕경제 (moral economy)’론은 바로 이처럼 경제 현상에서 규범이나 문화의 역할 문제 를 다루는 접근 방식이다. 이러한 시도는 경제와 관련된 사회 현상을 이해하는 데 에서 경제학적 접근 방식의 편협성과 한계를 해결하는 데에도 풍부한 시사점을 줄수있을것이다. 이논문은기존의도덕경제론에서다룬주요쟁점과개념을 소개하고, 이 논의가 미디어 경제를 이해하는 데 주는 함의, 쟁점 등을 검토한다.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tokenizer('천하통일', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[12673, 13586, 21780]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**input.to(device), labels=label['input_ids'].to(device))#, output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.decoder_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.select(range(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]]), 'input_ids': tensor([[10888, 14396, 19255,  ...,     3,     3,     3],\n",
       "        [16446, 12126, 14575,  ...,  3020, 18037, 14098]]), 'labels': tensor([[15352, 14453, 14073, 16439, 14285, 14518, 17469, 15095, 20044, 14653,\n",
       "         11863, 14718,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [16446, 12024, 14029, 12041, 14139, 13714, 14256, 17664, 14028, 14040,\n",
       "         12123, 14338,  4543,  8813, 12024,  1700,  3486,  4400,  1700,  4336,\n",
       "          2682,  1700,  4823,  5996,  9120, 14028,  1700,  3095,  3704,   240]]), 'decoder_input_ids': tensor([[    2, 15352, 14453, 14073, 16439, 14285, 14518, 17469, 15095, 20044,\n",
       "         14653, 11863, 14718,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
       "        [    2, 16446, 12024, 14029, 12041, 14139, 13714, 14256, 17664, 14028,\n",
       "         14040, 12123, 14338,  4543,  8813, 12024,  1700,  3486,  4400,  1700,\n",
       "          4336,  2682,  1700,  4823,  5996,  9120, 14028,  1700,  3095,  3704]])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "output = model(**data_collator(features).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5473, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[3][0][0][0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "981f108a204f421f158e0977940335d851edffa6dd3586828a3e1aec045160e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('final': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
