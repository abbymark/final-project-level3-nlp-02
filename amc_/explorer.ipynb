{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "import transformers\n",
    "from huggingface_hub import notebook_login\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1yb69i6e) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4089... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aba618fce5f4e748a89d2ed7dc1fde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">sleek-cosmos-1</strong>: <a href=\"https://wandb.ai/abbymark/final_project/runs/1yb69i6e\" target=\"_blank\">https://wandb.ai/abbymark/final_project/runs/1yb69i6e</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211204_130630-1yb69i6e/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1yb69i6e). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/abbymark/kobart/runs/3fp83k6i\" target=\"_blank\">feasible-night-1</a></strong> to <a href=\"https://wandb.ai/abbymark/kobart\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/abbymark/kobart/runs/3fp83k6i?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9a9c2f2fa0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "wandb.init(project='kobart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset paper_summarization (/opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/2.2.0/46d835d4e22daa3a5a46d13de39e3d75f6c2eaef5ead153d48cbe8d7cd3bec9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bf2adff2da4ef997f6c1d62a9e9226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api_token = os.getenv('HF_DATASET_API_TOKEN')\n",
    "dataset = datasets.load_dataset('metamong1/summarization_paper', use_auth_token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['doc_id', 'title', 'text', 'doc_type', 'file'],\n",
       "        num_rows: 73640\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['doc_id', 'title', 'text', 'doc_type', 'file'],\n",
       "        num_rows: 18411\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking dataset content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(dataset, datasets.dataset_dict.DatasetDict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=seed):\n",
    "    if isinstance(dataset, datasets.dataset_dict.DatasetDict):\n",
    "        sample = dataset['train'].shuffle(seed=seed).select(range(num_samples))\n",
    "    elif isinstance(dataset, datasets.arrow_dataset.Dataset):\n",
    "        sample = dataset.shuffle(seed=seed).select(range(num_samples))\n",
    "    else:\n",
    "        raise ValueError('Inappropriate dataset.')\n",
    "    for example in sample:\n",
    "        print(f\"\\n'>> Title: {example['title']}'\")\n",
    "        print(f\"'>> Text: {example['text']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 'A201008192682',\n",
       " 'title': '횡적등방성 매질에서 중합전 역시간 구조보정',\n",
       " 'text': '역시간 구조보정은 음원영역 파동장 외삽과 수진기영역 파동장 외삽의 상호상관으로 지층구조를 영상화하는 방법으로 복잡한 등방성 매질 층서구조를 영상화하는데 주로 이용된다. 그러나 일반적으로 지구내부 지층구조는 이방성 특성을 지니고 있으므로 이방성을 고려한 구조보정 기술이 필요하다. 여기에서는 편미분 파동장과 음원모음의 내적에 의한 알고리즘과 가상음원과 역전파 파동장과의 내적에 의한 알고리즘을 이용하여 횡적등방성 매질에서 역시간 구조보정 기술을 개발하고자 하였다. 단순 이방성 지층모델에 대한 수치모형실험 결과, 두 가지 방법에 의한 지층단면도 영상은 거의 차이가 없어 가상음원과 역전파 파동장과의 내적으로 구조보정을 실시하는 것이 효과적임을 알 수 있었다. 수평적으로 속도가 변하는 이방성 매질 지층구조에서 편미분 파동장을 구하지 않고 영상화 할 수 있음을 알 수 있었다.',\n",
       " 'doc_type': '논문',\n",
       " 'file': '논문요약_0206_0.json'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/2.2.0/46d835d4e22daa3a5a46d13de39e3d75f6c2eaef5ead153d48cbe8d7cd3bec9c/cache-349ab71b5c228bee.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: 민주주의 관점으로 본 국가기록관리체계 평가와 전망'\n",
      "'>> Text: 본 논문은 국가기록관리체계를 민주주의 관점에서 보았다. 지난 10년의 국가기록관리체계를 평가하고 새로운 국가기록관리체계를 전망하기위해서는 민주주의가 우선이 되어야 할 것 같다. 지난 10년의 아카이브가쭈그러진 아카이브였다면, 새로운 아카이브는 어떤 아카이브이어야 할까? 쭈그러진 깡통을 펴듯이 망가지기 전의 상태로 복구하는 게 필요한 일인줄 알면서도 새로운 기록풍경을 그리는 것도 그 못지않게 중요하다고 보았다. 본 논문은 기본적으로 민주주의의 가치를 제도화하는 아카이브 전망에대한 것이다. 나아가 일상적 민주주의에서 아카이브는 무엇을 할 수 있을지도 짚어보았다. 이를 위해 그간의 국가기록관리기구 개편 제안을 체계적으로 검토했다. 그 다음에는 공공기록관 기록관리직의 목소리를 재현해보았다. 기록관리직은 지난 10년 동안 기록공동체와 우리 사회가 일군 사회적자산이기 때문에 그 목소리가 무엇을 원하는지 들어야 한다고 판단했기 때문이다. 기록은 이제 단순히 통치의 수단이 아니라 그 통치의 정통성을 규정하는 통치의 기반이 되었다. 이처럼 기록의 사회적 역할과 의미가 달라졌다. 1999년 시점이 아닌 2017년 시점에서, 국가아카이브의 기록풍경을 다시 그려야 할 것이다. 이런 과제를 위해서는 무엇보다도 민주주의 관점이 필요하다고 생각한다.'\n",
      "\n",
      "'>> Title: 조선의 대일 교화 양상과 그 기저 (朝鮮의 對日 敎化 樣相과 그 基底)'\n",
      "'>> Text: 조선전기는 왜구의 잦은 침탈로 인해 일본과의 외교적 해결이 절실히 요구되던 때였다. 그러나 막부의 왜구 통제력 부족으로 교섭이 번번이 무위로 돌아갔다. 그와 같은 상황이 지속되자 명쾌한 대책을 마련하지 못한 조선은 信義를 잃은 일본에 대하여 夷狄으로 대하거나 小國으로 여기는 입장을 취하였다. 이러한 당시의 대일 관계는 문인들에 의해 시문으로 구현되었다. 하지만 시문을 살펴보면, 현안인 왜구를 근절하는 데에만 집중한 나머지 조일 간의 다양한 교류의 면모는 찾을 수 없고 왜구 금압이라는 한 측면에만 경사되어 있음을 발견하게 된다. 이것은 왜구 문제가 조일 간의 정상적인 문화 교류를 저해하였다는 점에서 안타까운 일이 아닐 수 없고 문학사에서도 아쉬움으로 남는 부분이다. 왜구의 창궐이 심할수록 교화의 당위성은 제고되었으나 직접 왜구를 대면하여 교화할 길이 없었던 당대 문인들은 일본국왕사나 통신사에게 주는 시문으로나마 교화의 뜻을 일본에 전하고자 하였다. 그 대상이 왜구여야 함에도 실체가 모호하였기에 일본국왕을 상대로 전개될 수밖에 없는 한계가 있었다. 본고에서는 조일 양국의 교류에 대한 연구가 유형적인 것에 편향되었다는 반성에서, 조선전기 시문에 나타난 대일 교화의 양상과 그 기저를 밝히는 데 중점을 두었다. 교화의 양상으로는 먼저 조선이 교화의 주체로 나서고자 箕子와 찬란한 문물로써 태평시대임을 부각시키려 한 것을 들 수 있다. 그것은 조선의 정치가 안정되고 문화가 난숙하였던 기반 위에서 나왔으며 그 동인은 ‘恕’와 ‘位育’이라는 유가의 치도였다. 우수한 문물로 인한 문화적 우월감과 유가의 불가에 대한 우위는 ‘兩國一家’라는 교화의 기치로 이어진다. 교화라는 말이 관념적이라서 양국일가에 장애가 되는 험난한 동해를 교화로 고요히 하려는 관념성을 띠었고, 더 나아가 교화를 ‘雲雨’나 ‘雨露’로써 비유하여 표현하기도 하였다. 이러한 교화의 양상을 보인 기저에는 ‘仁’과 ‘圓’이 있었다. 교화의 기저 가운데 ‘仁’은 무력보다는 덕을 높이고 따스한 햇볕과 같이 만물을 비추어 소생시키는 지향을 지녔다. 우주론적 인식에 근거하면 일본은 ‘仁’의 방향이 되는데, 그 점은 실제 왜구가 벌인 만행과는 모순되지만 왜구를 금제할 이론적 근거이면서 동시에 그들의 ‘인’을 감발시키는 계기가 되었다. ‘圓’은 만물의 운행 원리로, 조일 간의 교린에도 적용되기를 바랐다. ‘圓’의 실제적 의미는 교린에서의 信義를 뜻하였지만, 교화의 기저 가운데 하나로서 교화가 단절되지 않도록 도와주는 기능이었다. ‘仁’과 ‘圓’의 층위가 달라 구분이 무의미하기는 하지만 ‘仁’이 일본의 人性을 계발하는 교화의 핵심적 기저라면 ‘圓’은 그것을 보조하는 주변적 기저라고 할 수 있겠다.'\n",
      "\n",
      "'>> Title: 농촌지역 노령인구의 통행패턴 분석- 경상북도 봉화군 지역을 중심으로 -'\n",
      "'>> Text: 농촌이라는 지역적 조건과 노인이라는 신체적, 경제적, 그리고 사회적 조건을 고려할 때 우리나라 농촌지역에 거주하는 노인들은 이동 및 접근의 제약으로 인하여 공간적 고립 및 사회적 배제과정에 노출될 가능성이 매우 높은 집단이라고 할 수 있다. 그러나 특정 집단의 교통으로 인한 사회적 배제 문제를 분석하기 위해서는 이들의 개인적 특성에 따른 통행패턴에 대한 이해가 전제되어야 한다. 하지만 우리나라에서는 농촌노인들의 통행에 관련된 연구 성과가 매우 미흡하며 따라서 이들 인구의 개인적 특성에 따른 통행패턴에 대한 연구의 필요성이 매우 크다. 이러한 배경에서 본 연구는 농촌지역에 거주하는 노인들을 대상으로 이들의 개인적 특성과 통행패턴 간의 연관성을 분석하였다. 연구지역 노인들의 통행특성은 이들의 신체적, 경제적, 그리고 사회적 배경 등의 요인들에 따라 매우 다양하게 나타나고 있다. 특히 농촌지역이라는 지역적 특성으로 인하여 이들의 신체적 건강상태 및 경제적 능력 등에 따른 자가용 승용차 이용 정도는 이들의 이동과정에 매우 큰 영향을 미치고 있다. 그러나 현실적으로 우리나라 농촌에 거주하는 많은 노인들은 자가용 이용 능력이 없으며, 또한 현재 농촌에서 운영 중인 버스를 중심으로 한 대중교통체계가 자가용 승용차와 같은 개인적이며 유연적인 통행을 제공할 수 없다. 이러한 점들을 고려할 때 우리나라 농촌노인들은 이동의 제약으로 인한 공간적 고립, 그리고 더 나아가 교통으로 인한 사회적 배제 과정에 노출 될 수 있는 가능성이 매우 높다고 할 수 있다. 따라서 앞으로 본 연구결과를 바탕으로 이러한 농촌노인들의 개인적 특성에 따른 통행특성 그리고 이에 따른 이동의 제약 등의 요인들이 이들의 공간적 고립 내지는 사회적 배제 과정에 미치는 영향에 대한 연구의 필요성이 매우 절실하다.'\n"
     ]
    }
   ],
   "source": [
    "show_samples(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/2.2.0/46d835d4e22daa3a5a46d13de39e3d75f6c2eaef5ead153d48cbe8d7cd3bec9c/cache-349ab71b5c228bee.arrow\n"
     ]
    }
   ],
   "source": [
    "sample_size = 1000\n",
    "sample_training_dataset = dataset['train'].shuffle(seed=seed).select(range(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/2.2.0/46d835d4e22daa3a5a46d13de39e3d75f6c2eaef5ead153d48cbe8d7cd3bec9c/cache-781b22210d45164a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: 탄소라벨링 브랜드 충성도를 결정하는 요인: 가치-­태도­-행동 모형의 적용'\n",
      "'>> Text: 기후변화와 온실가스 감축에 대한 사회적 관심과 정부의 정책이 증가하는 요즘 탄소 라벨링 제도는 저탄소 생산과 저탄소 소비를 연결하는 환경정책으로 시장에 점차 확대되고 있다. 따라서 탄소 라벨링 제품에 대한 소비자 태도와 브랜드 충성도를 분석하기 위하여 탄소 라벨링 소비자 모형을 제시하여, 소비자의 내재된 가치가 탄소 라벨링 제품 및 기업 이미지 형성에 영향을 주고 나아가 브랜드 충성도를 제고하는 과정을 분석하였다. 2차에 걸친 설문조사를 통해 패널 데이터를 수집하여 분석한 결과 소비자의 자율성 가치는 지각된 통제소재에 긍정적인 영향을 주고 기업 이미지를 긍정적으로 형성시켰으며, 환경적 가치는 지각된 소비자 효과를 높이고, 나아가 지각된 장애를 줄임으로써 제품 이미지에 영향을 미침을 확인하였다. 궁극적으로, 긍정적인 기업 이미지와 제품 이미지는 브랜드 충성도를 향상시켰다. 이와 같은 결과는 탄소 라벨링 정책이 기후변화 대응을 위해 온실가스를 감축하는 데 도움이 될 뿐만 아니라 동시에 소비자의 기업 및 제품에 대한 이미지와 브랜드 충성도를 향상시키는 순기능이 있음을 보여준다. 탄소 라벨링 정책이 소비자 태도와 브랜드 충성도에 미치는 영향을 분석하는 고유의 모형을 제시하고 실증분석한 점에 그 학문적 기여도가 높다고 하겠다. 더욱이, 연구결과는 정부에게 환경정책의 효율성을 높이기 위한 정책제언을 제시하고 있고, 기업에게도 탄소 라벨링과 관련된 마케팅 전략의 방향성을 제안하고 있다는 점에서 실무적 공헌을 갖고 있다.'\n",
      "\n",
      "'>> Title: 3DTV 구매의도에 영향을 미치는 요인에 대한 연구'\n",
      "'>> Text: 본 연구는 3DTV의 구매의도에 영향을 미치는 요인들을 인지적 요인과 감정적 요인으로 접근하였으며 긍정적 측면과 부정적 측면을 함께 고려하여 살펴보았다. 3DTV의 수용에 영향을 미치는 인지적 요인으로써‘지각된 유용성’과‘지각된 사용의 용이성’, 그리고‘지각된 비용’을 탐구하였다. ‘ 지각된 유용성’과 ‘지각된 사용의 용이성’이 3DTV의 수용에 긍정적인 영향을 주는 인지적 요인이라면 지각된 비용은 제품의 수용에 부정적인 영향을 주는 인지적 요인이다. 3DTV의 수용에 영향을 미치는 감정적 요인으로는 긍정적인 영향을 주는 ‘지각된 즐거움’과 부정적인 영향을 주는 ‘예상된 후회’를 채택하였다. 이외에도 본 연구는 ‘지각된 품질’을 기술수용모델의 선행요인으로 포함하였다. 실제 매장을 방문한 고객들을 대상으로 구조방정식 모델을 이용하여 분석한 결과 첫째, 지각된 품질이 지각된 사용의 즐거움에 가장 큰 영향력을 미치는 선행요인으로 나타났다. 둘째, 지각된 유용성, 지각된 즐거움, 그리고 지각된 사용의 용이성의 순서로 태도와 구매의도에 긍정적인 영향을 미치는 것으로 나타났다. 셋째, 지각된 비용은 3DTV의 태도 형성에 예상된 후회는 구매의도에 부정적인 영향을 주는 영향요인임이 밝혀졌다.'\n",
      "\n",
      "'>> Title: 대학 유연전공의 효과와 개선전략'\n",
      "'>> Text: 본 연구는 우리나라 대학에서 이루어지고 있는 유연전공의 효과, 운영 현황, 그리고 개선전략을 알아보는 것을 목적으로 수행하였다. 유연전공의 효과는 양적 연구를 통해, 그리고 유연전공의 현황과 운영 개선전략은 질적 연구를 통해 실시하였다. 유연전공 효과 분석 결과에 의하면 측정한 대부분의 역량에서 유연전공 참여 경험이 있는 학생들이 참여 경험이 없는 학생들에 비해 평균 점수가 높은 것으로 나타났다. 한편, 유연전공 개발과 참여 경험이 있는 전문가 집단에 대한 면접 조사 내용을 분석한 결과, 우리나라 대학의 유연전공은 활성화에 유리한 외부적 환경과 이를 저해하는 대학 내부 문화가 교차하는 지점에 위치해 있으며, 구성원들의 공감대 형성에 기초한 참여의지 확산 및 전담조직의 설치를 통한 인적·물적 자원의 확대가 핵심적인 개선전략이었다. 본 연구를 종합해 볼 때 기존의 전공중심 대학 문화에 대한 도전으로 시작된 유연전공 제도의 전망은 비교적 밝은 것으로 평가할 수 있다.'\n"
     ]
    }
   ],
   "source": [
    "show_samples(sample_training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/final/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"gogamza/kobart-summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [12147, 10608, 14106, 14403, 14353, 26200, 24224, 14667, 14150, 14803, 24110, 11465, 9754, 232], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"제목 생성을 위한 요약 모델을 이제부터 만들어 봅시다!\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['제',\n",
       " '목',\n",
       " '▁생',\n",
       " '성을',\n",
       " '▁위한',\n",
       " '▁요약',\n",
       " '▁모델을',\n",
       " '▁이제',\n",
       " '부터',\n",
       " '▁만들어',\n",
       " '▁봅',\n",
       " '시',\n",
       " '다',\n",
       " '!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['text'], max_length=max_input_length, truncation = True, #padding=True\n",
    "    )\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples['title'], max_length=max_target_length, truncation=True, #padding=True\n",
    "        )\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13eaa7f3e78f4f79901d72af41f784b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = sample_training_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Korean Sentence Splitter]: Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/metamong1___paper_summarization/Paper Summarization/2.2.0/46d835d4e22daa3a5a46d13de39e3d75f6c2eaef5ead153d48cbe8d7cd3bec9c/cache-34efb215017ddbce.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_eval_datasets = dataset['validation'].select(range(500)).map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_metric\n",
    "# rouge_score = load_metric('rouge')\n",
    "\n",
    "import os, sys\n",
    "sys.path.append('/opt/ml/final-project-level3-nlp-02')\n",
    "from rouge import compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(precision=0.7368421052631579, recall=0.875, fmeasure=0.7999999999999999)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summary = \"이번 제목 생성 테스크 진짜 진짜 잘하고 싶다. 두번째줄은 작동 안한다고?\"\n",
    "reference_summary = \"이번 제복 생성 테스크 잘하고 싶다. 두번째 작동 안한다고?\"\n",
    "# generated_summary = \"I absolutely loved reading the Her Games\"\n",
    "# reference_summary = \"I loved reading the Hunger Games\"ung\n",
    "scores = compute(\n",
    "    predictions=[generated_summary], references=[reference_summary], tokenizer=tokenizer\n",
    ")\n",
    "scores['rouge1'].mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "def one_sentence_title(text):\n",
    "    return kss.split_sentences(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 논문은 국가기록관리체계를 민주주의 관점에서 보았다.\n"
     ]
    }
   ],
   "source": [
    "print(one_sentence_title(sample_training_dataset['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(dataset, tokenizer):\n",
    "    summaries = [one_sentence_title(text) for text in dataset['text']]\n",
    "    return compute(predictions=summaries, references=dataset['title'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 19.64, 'rouge2': 11.76, 'rougeL': 19.08, 'rougeLsum': 19.06}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = evaluate_baseline(dataset['validation'].shuffle().select(range(10)), tokenizer)\n",
    "rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "rouge_dict = dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/gogamza/kobart-summarization/resolve/main/config.json from cache at /opt/ml/.cache/huggingface/transformers/1c32baaf6a1067a5e27a0dfbac0a3d23a86d958ab10b092d5ea4150bd451de17.4e52ef6c87e6938c92ba0d19888607d76e30e950e81060a8fa6cb1189c93614d\n",
      "/opt/conda/envs/final/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.11.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gogamza/kobart-summarization/resolve/main/pytorch_model.bin from cache at /opt/ml/.cache/huggingface/transformers/f30ba9ba60f377194e6a39913246c76f6dcac8158e399598ed56fec262103dba.b063b56b256aaf29f8c7c67e318ed78b83b9381147ac794d0df9ef0399066ea7\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-summarization.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f'{model_name}-finetuned-paper-sample-size-1000',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay = 0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to='wandb'\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    # decoded_preds = ['\\n'.join(kss.split_sentences(pred.strip())) for pred in decoded_preds]\n",
    "    # decoded_labels = ['\\n'.join(kss.split_sentences(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    result = compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, tokenizer=tokenizer, use_stemmer=True\n",
    "    )\n",
    "\n",
    "    # Extract the median scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets[5]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_return = ['input_ids', 'labels', 'attention_mask']\n",
    "tokenized_datasets.set_format(type='torch', columns = columns_to_return, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]]), 'input_ids': tensor([[10888, 14396, 19255,  ...,     3,     3,     3],\n",
       "        [16446, 12126, 14575,  ...,  3020, 18037, 14098]]), 'labels': tensor([[15352, 14453, 14073, 16439, 14285, 14518, 17469, 15095, 20044, 14653,\n",
       "         11863, 14718,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [16446, 12024, 14029, 12041, 14139, 13714, 14256, 17664, 14028, 14040,\n",
       "         12123, 14338,  4543,  8813, 12024,  1700,  3486,  4400,  1700,  4336,\n",
       "          2682,  1700,  4823,  5996,  9120, 14028,  1700,  3095,  3704,   240]]), 'decoder_input_ids': tensor([[    2, 15352, 14453, 14073, 16439, 14285, 14518, 17469, 15095, 20044,\n",
       "         14653, 11863, 14718,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
       "        [    2, 16446, 12024, 14029, 12041, 14139, 13714, 14256, 17664, 14028,\n",
       "         14040, 12123, 14338,  4543,  8813, 12024,  1700,  3486,  4400,  1700,\n",
       "          4336,  2682,  1700,  4823,  5996,  9120, 14028,  1700,  3095,  3704]])}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tokenized_datasets[i] for i in range(2)]\n",
    "data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_eval_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: file, text, doc_type, doc_id, title.\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   7/1000 00:55 < 3:04:58, 0.09 it/s, Epoch 0.05/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3285/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/final/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/final/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/final/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/final/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "981f108a204f421f158e0977940335d851edffa6dd3586828a3e1aec045160e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('final': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
